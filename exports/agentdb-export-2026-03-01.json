{
  "exportedAt": "2026-03-01T10:07:00Z",
  "backend": "sql.js + HNSW",
  "version": "3.0.0",
  "totalEntries": 12,
  "embeddingDimensions": 384,
  "namespaces": {
    "knowledge": 7,
    "patterns": 5
  },
  "entries": [
    {
      "key": "auto-memory-project-context",
      "namespace": "knowledge",
      "value": "Claude Flow V3 Project Memory. THG World Record Attempt campaign. Date: 2026-03-01. Key repos: campaign/THG-world-record-attempt (git@github.com:DreamLab-AI/THG-world-record-attempt.git). Infrastructure: turbo-flow-unified container, ruvector-postgres:5432, ComfyUI, Blender 5.x MCP. VFX Pipeline: 4-step (Segmentation->SAM3D->GeoTracker->Compositor). Memory files: vfx-pipeline.md, blender5x-api.md, geotracker-api.md.",
      "tags": ["auto-memory", "project", "context", "thg"],
      "storedAt": "2026-03-01T10:06:39.777Z",
      "hasEmbedding": true
    },
    {
      "key": "vfx-pipeline-status",
      "namespace": "knowledge",
      "value": "VFX Pipeline 4-Step Status: Step 1 Segmentation (GroundingDINO+SAM2) WORKING - clean cutout tested on elephant.png. Step 2 SAM3D Recon (SAM3DGenerateSLAT) BLOCKED - corrupt checkpoint, use --glb-override. Step 3 GeoTracker (KeenTools v2025.3.0) WORKING - tracking succeeds, bake uses fallback. Step 4 Compositor (Blender 5.x nodes) WORKING - 3 test frames rendered 2560x1440. CLI: python -m vfx_pipeline.pipeline --video /path/video.mp4 --prompt \"the red car\" --output /tmp/out. GLB meshes at /home/devuser/workspace/project/multi-agent-docker/comfyui/storage-output/sam3d_inference_5/mesh.glb (34MB best quality).",
      "tags": ["vfx", "pipeline", "status", "thg"],
      "storedAt": "2026-03-01T10:06:47.100Z",
      "hasEmbedding": true
    },
    {
      "key": "thg-campaign-pipeline",
      "namespace": "knowledge",
      "value": "THG World Record Campaign Pipeline: 7 phases. Phase 1 Asset Generation (Flux2+SDXL, 45 assets, 12min). Phase 2 Video Generation (Veo3.1+Kling, 30 clips, 25min). Phase 3 3D Asset Creation (SAM3D+Meshy, 15 models, 18min). Phase 4 VFX/Tracking (GeoTracker+Blender, 20 shots, 15min). Phase 5 Compositing (Blender5x+Nuke, 20 comps, 10min). Phase 6 Audio/Music (Udio+ElevenLabs, 8 tracks, 8min). Phase 7 Final Assembly (DaVinci+FFmpeg, 1 master, 10min). Totals: 138 assets, 96min wall clock, 8-14x speedup target. Quality gates: FID<15, CLIP>0.85, VMAF>90.",
      "tags": ["thg", "campaign", "pipeline", "phases"],
      "storedAt": "2026-03-01T10:06:54.977Z",
      "hasEmbedding": true
    },
    {
      "key": "thg-topshop-brand",
      "namespace": "knowledge",
      "value": "Topshop SS26 Brand Identity: Campaign \"Neon Pulse\". Primary #FF1493 DeepPink, Secondary #00FFFF Cyan, Accent #FFD700 Gold, Background #0A0A0A NearBlack. Typography: Bebas Neue (headlines), Inter (body), JetBrains Mono (tech). AI Engines: Flux2 (hero stills), Veo3.1 (video), Kling2.1 (motion), SAM3D (3D), ElevenLabs (voice), Udio (music). Container: turbo-flow-unified, 64GB RAM, RTX4090, ports 8080/5901/9090. Editorial direction: high-fashion meets cyberpunk, neon-lit urban environments.",
      "tags": ["thg", "topshop", "brand", "campaign"],
      "storedAt": "2026-03-01T10:06:58.702Z",
      "hasEmbedding": true
    },
    {
      "key": "thg-shot-concepts",
      "namespace": "knowledge",
      "value": "THG Shot Concepts (8 editorial shots): 1) neon-runway - Model walks neon-lit runway, volumetric fog, Flux2. 2) chrome-reflection - Model reflected in chrome surfaces, rain-slicked street, Veo3.1. 3) holographic-display - Model interacts with holographic fashion displays, Kling2.1. 4) rooftop-golden - Golden hour rooftop, city skyline, wind-blown fabric, Flux2. 5) underwater-fabric - Fabric flowing underwater, bioluminescent particles, Veo3.1. 6) mirror-maze - Infinite reflections in mirror installation, Flux2. 7) neon-garden - Model in bioluminescent garden, organic meets synthetic, Kling2.1. 8) data-storm - Model in data visualization storm, particle effects, Veo3.1.",
      "tags": ["thg", "shots", "concepts", "editorial"],
      "storedAt": "2026-03-01T10:07:03.827Z",
      "hasEmbedding": true
    },
    {
      "key": "technical-findings-flux2-veo",
      "namespace": "knowledge",
      "value": "Technical Findings Summary: Flux2 - best quality stills, 12-step inference optimal, CFG 7.5, resolution 1024x1024 native then upscale. Multi-GPU - data parallel across 2xRTX4090 gives 1.8x speedup for batch generation. Nano Banana - serverless GPU inference, cold start 8-12s, warm 0.5-1s, cost-effective for burst workloads. Veo 3.1 - 1080p video generation, 4s clips, temporal consistency good at CFG 6, motion amount 0.7. Text compositing - Bebas Neue renders cleanly at 72pt+, use white with black outline for visibility on neon backgrounds. DaVinci Resolve - best for final assembly, Fusion for motion graphics, Fairlight for audio.",
      "tags": ["thg", "technical", "flux2", "veo", "findings"],
      "storedAt": "2026-03-01T10:07:10.885Z",
      "hasEmbedding": true
    },
    {
      "key": "container-environment",
      "namespace": "knowledge",
      "value": "Turbo Flow Container Environment: Container turbo-flow-unified (rebuilt 2026-02-03). External memory: ruvector-postgres:5432 (DB ruvector, 1.17M+ entries, HNSW indexed). Docker network: docker_ragflow. Users: devuser(1000), gemini-user(1001), openai-user(1002), zai-user(1003), deepseek-user(1004). Ports: SSH 22->2222, VNC 5901, code-server 8080, Management API 9090, Z.AI 9600. 610 sub-agents at /home/devuser/agents/*.md. tmux workspace with 8 windows. supervisorctl requires sudo. npx slower than global claude-flow binary.",
      "tags": ["container", "environment", "infrastructure"],
      "storedAt": "2026-03-01T10:07:17.074Z",
      "hasEmbedding": true
    },
    {
      "key": "blender5x-api-changes",
      "namespace": "patterns",
      "value": "Blender 5.x Breaking API Changes: 1) scene.node_tree REMOVED -> use scene.compositing_node_group. 2) Must create via bpy.data.node_groups.new(\"Compositing\",\"CompositorNodeTree\") and assign. 3) CompositorNodeComposite REMOVED -> use NodeGroupOutput + cng.interface.new_socket(). 4) AlphaOver inputs reordered: [0]=Background [1]=Foreground [2]=Factor (use named inputs). 5) BLENDER_EEVEE_NEXT -> BLENDER_EEVEE. 6) FFMPEG not in image_settings.file_format -> render PNG frames. 7) exec() scoping: imports not visible in nested functions, for-loop vars undefined. 8) use_empty=True creates scene without world/lights - must add manually.",
      "tags": ["blender", "api", "breaking-changes", "5x"],
      "storedAt": "2026-03-01T10:06:53.806Z",
      "hasEmbedding": true
    },
    {
      "key": "geotracker-keentools-api",
      "namespace": "patterns",
      "value": "GeoTracker KeenTools v2025.3.0 API: Create via bpy.ops.keentools_gt.create_geotracker(). Access: settings=bpy.context.scene.keentools_gt, gt=settings.get_current_geotracker(). Set movie clip: gt.movie_clip=clip. Set geometry: gt.geomobj=mesh_obj. Track: bpy.ops.keentools_gt.track_to(). Bake: bpy.ops.keentools_gt.bake_from_selected_frames(). Refine: bpy.ops.keentools_gt.refine_async(). Key props: gt.focal_length, gt.tracking_quality_threshold=0.3. Fallback: if bake fails use matrix_world assignment per frame. KeenTools ships as Blender addon - must be pre-installed in container.",
      "tags": ["geotracker", "keentools", "blender", "api"],
      "storedAt": "2026-03-01T10:06:59.944Z",
      "hasEmbedding": true
    },
    {
      "key": "comfyui-node-names",
      "namespace": "patterns",
      "value": "ComfyUI Verified Node Names: GroundingDinoModelLoader (segment anything2) model_name=\"GroundingDINO_SwinT_OGC (694MB)\". SAM2ModelLoader (segment anything2) model_name=\"sam2_hiera_tiny\". GroundingDinoSAM2Segment (segment anything2) needs keep_model_loaded. LoadSAM3DModel outputs: depth_model,generator,slat_decoder_gs,slat_decoder_mesh. SAM3D_DepthEstimate, SAM3DGenerateSLAT, SAM3DMeshDecode, SAM3DGaussianDecode, SAM3DTextureBake outputs glb_filepath as STRING. Preview3D for 3D preview. /free endpoint returns empty body - don't JSON-parse.",
      "tags": ["comfyui", "nodes", "sam3d", "segmentation"],
      "storedAt": "2026-03-01T10:07:06.588Z",
      "hasEmbedding": true
    },
    {
      "key": "daemon-worker-performance",
      "namespace": "patterns",
      "value": "Claude-Flow Daemon Worker Performance (1,449 total runs): optimize - 298 runs, 99.0% success, avg 1847ms. testgaps - 276 runs, 98.6% success, avg 1623ms. audit - 245 runs, 98.0% success, avg 2156ms. document - 218 runs, 97.7% success, avg 1534ms. map - 194 runs, 97.4% success, avg 2890ms. deepdive - 156 runs, 96.8% success, avg 3245ms. complexity - 62 runs, 95.2% success, avg 1892ms. Triggers: optimize on major refactor, testgaps on new features, audit on security changes, document on API changes, map on 5+ file changes, deepdive on complex debug.",
      "tags": ["daemon", "workers", "performance", "metrics"],
      "storedAt": "2026-03-01T10:07:15.754Z",
      "hasEmbedding": true
    },
    {
      "key": "vfx-pipeline-fixes",
      "namespace": "patterns",
      "value": "VFX Pipeline Key Fixes Applied: 1) TBG-SAM3 replaced with GroundingDINO+SAM2 (opencv-headless conflict). 2) SAM3D nodes refactored (SAM3DSparseGen removed -> SAM3DGenerateSLAT). 3) ComfyUI /free returns empty body -> don't JSON-parse. 4) subprocess_bridge.py missing import os -> fixed. 5) pyvista missing in SAM3D venv -> installed with --target. 6) Blender 5.x compositor API completely changed (compositing_node_group). 7) AlphaOver inputs reordered: [0]=Background [1]=Foreground. 8) BLENDER_EEVEE_NEXT -> BLENDER_EEVEE. 9) FFMPEG not in image_settings -> render PNG frames. 10) exec() scoping issues in Blender MCP -> simplified scripts.",
      "tags": ["vfx", "fixes", "debugging", "pipeline"],
      "storedAt": "2026-03-01T10:07:20.855Z",
      "hasEmbedding": true
    }
  ]
}
